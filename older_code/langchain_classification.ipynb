{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d05c9b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63be0ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a3243ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using langchain message types\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2, timeout=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4489d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "tagging_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Extract the desired information from the following passage.\n",
    "\n",
    "Only extract the properties mentioned in the 'Classification' function.\n",
    "\n",
    "Passage:\n",
    "{input}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "class Classification(BaseModel):\n",
    "    sentiment: str = Field(description=\"The sentiment of the text\")\n",
    "    aggressiveness: int = Field(\n",
    "        description=\"How aggressive the text is on a scale from 1 to 10\"\n",
    "    )\n",
    "    language: str = Field(description=\"The language the text is written in\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8288c640",
   "metadata": {},
   "source": [
    "## Passing a Pydantic class to LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7580ddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structured LLM\n",
    "structured_llm = model.with_structured_output(Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77cd0de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'contento', 'aggressiveness': 0, 'language': 'es'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = \"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\"\n",
    "prompt = tagging_prompt.invoke({\"input\": inp})\n",
    "response = structured_llm.invoke(prompt)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c248247a",
   "metadata": {},
   "source": [
    "## Finer Control\n",
    "Specifically, we can define:\n",
    "\n",
    "Possible values for each property \\\n",
    "Description to make sure that the model understands the property \\\n",
    "Required properties to be returned \\\n",
    "Let's redeclare our Pydantic model to control for each of the previously mentioned aspects using enums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f41891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class my_sentiment(str, Enum):\n",
    "    HAPPY = \"happy\"\n",
    "    NEUTRAL = \"neutral\"\n",
    "    SAD = \"sad\"\n",
    "\n",
    "\n",
    "class Classification1(BaseModel):\n",
    "    sentiment: str = Field(description=\"The sentiment of the text\")\n",
    "    aggressiveness: int = Field(\n",
    "        ...,\n",
    "        description=\"describes how aggressive the statement is, the higher the number the more aggressive\",\n",
    "        enum=[1, 2, 3, 4, 5],\n",
    "    )\n",
    "    language: str = Field(\n",
    "        ..., enum=[\"spanish\", \"english\", \"french\", \"german\", \"italian\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f5d6981",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Extract the desired information from the following passage.\n",
    "\n",
    "Only extract the properties mentioned in the 'Classification' function.\n",
    "\n",
    "Passage:\n",
    "{input}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# add structured output directly into the llm invokation\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\").with_structured_output(\n",
    "    Classification1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64f0d3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'contento', 'aggressiveness': 0, 'language': 'es'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = \"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\"\n",
    "prompt = tagging_prompt.invoke({\"input\": inp})\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e856967c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'enojado', 'aggressiveness': 8, 'language': 'es'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = \"Estoy muy enojado con vos! Te voy a dar tu merecido!\"\n",
    "prompt = tagging_prompt.invoke({\"input\": inp})\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8c90639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'ok', 'aggressiveness': 0, 'language': 'English'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = \"Weather is ok here, I can go outside without much more than a coat\"\n",
    "prompt = tagging_prompt.invoke({\"input\": inp})\n",
    "llm.invoke(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
